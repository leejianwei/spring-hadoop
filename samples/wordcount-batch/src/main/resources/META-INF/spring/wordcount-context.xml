<?xml version="1.0" encoding="UTF-8"?>
<beans:beans xmlns="http://www.springframework.org/schema/hadoop"
	xmlns:beans="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
        xmlns:batch="http://www.springframework.org/schema/batch"
        xmlns:p="http://www.springframework.org/schema/p"
	xsi:schemaLocation="http://www.springframework.org/schema/batch http://www.springframework.org/schema/batch/spring-batch-2.1.xsd
		http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
		http://www.springframework.org/schema/hadoop http://www.springframework.org/schema/hadoop/spring-hadoop.xsd">

	<batch:job id="job1">
		<batch:step id="import" next="wordcount">
			<batch:tasklet ref="script-tasklet"/>
		</batch:step>
			
		<batch:step id="wordcount">
			<batch:tasklet ref="wordcount-tasklet" />
		</batch:step>
	</batch:job>

	<tasklet id="wordcount-tasklet" job-ref="wc-job"/>

    <beans:bean name="pathUtils" class="org.springframework.data.hadoop.util.PathUtils" p:rootPath="${wordcount.output.path}"/>

    <beans:bean id="wc-job" class="org.springframework.data.hadoop.mapreduce.JobFactoryBean"
              p:configuration-ref="hadoop-configuration"
              p:input-paths="${wordcount.input.path}"
              p:output-path="#{@pathUtils.getTimeBasedPathFromRoot()}"
              p:mapper="org.apache.hadoop.examples.WordCount.TokenizerMapper"
              p:reducer="org.apache.hadoop.examples.WordCount.IntSumReducer"
              p:jar="${wordcount.jar.path}"
              p:validate-paths="false"
              scope="prototype"/>


	<script-tasklet id="script-tasklet">
  	   <script language="groovy">
  	   	// 'hack' default permissions to make Hadoop work on Windows
		if (System.getProperty("os.name").startsWith("Windows")) {
			// 0655 = -rwxr-xr-x
			 org.apache.hadoop.mapreduce.JobSubmissionFiles.JOB_DIR_PERMISSION.fromShort((short) 0655);
			 org.apache.hadoop.mapreduce.JobSubmissionFiles.JOB_FILE_PERMISSION.fromShort((short) 0655);
		}

  	   
		inputPath = "${wordcount.input.path:/user/gutenberg/input/word/}"
		outputPath = "${wordcount.output.path:/user/gutenberg/output/word/}"	
		if (fsh.test(inputPath)) {
		  fsh.rmr(inputPath)
		}
		if (fsh.test(outputPath)) {
		  fsh.rmr(outputPath)
		}

		// copy using the streams directly (to be portable across envs)
		inStream = cl.getResourceAsStream("data/nietzsche-chapter-1.txt")
		org.apache.hadoop.io.IOUtils.copyBytes(inStream, fs.create(inputPath), cfg)
	  </script>	
    </script-tasklet>

</beans:beans>
